---
permalink: transition/task_configure_transition.html 
sidebar: sidebar 
keywords: Generating and applying RCFs to the new IP switches, review, requirement, preparing, prepare, transition, perform, procedure, order, completing, complete, step, task, moving, move, controller, storage, shelves, shelf, exist, configuration, direct, metrocluster, fc, ip, verify, health, removing, remove, tiebreaker, monitor, software, generating, generate, apply, rcf, switch, controller, configure, prepare, preparing 
summary: Per preparare la configurazione per la transizione, aggiungere i nuovi nodi alla configurazione MetroCluster esistente e spostare i dati nei nuovi nodi. 
---
= Configurare MetroCluster per la transizione
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Per preparare la configurazione per la transizione, aggiungere i nuovi nodi alla configurazione MetroCluster esistente e spostare i dati nei nuovi nodi.



== Invio di un messaggio AutoSupport personalizzato prima della manutenzione

Prima di eseguire la manutenzione, devi inviare un messaggio AutoSupport per informare il supporto tecnico NetApp che la manutenzione è in corso. Informare il supporto tecnico che la manutenzione è in corso impedisce loro di aprire un caso partendo dal presupposto che si sia verificata un'interruzione.

.A proposito di questa attività
Questa attività deve essere eseguita su ciascun sito MetroCluster.

.Fasi
. Per impedire la generazione automatica del caso di supporto, inviare un messaggio AutoSupport per indicare che la manutenzione è in corso:
+
`system node autosupport invoke -node * -type all -message MAINT=maintenance-window-in-hours`

+
"`maintenance-window-in-hours`" specifica la lunghezza della finestra di manutenzione, con un massimo di 72 ore. Se la manutenzione viene completata prima che sia trascorso il tempo, è possibile richiamare un messaggio AutoSupport che indica la fine del periodo di manutenzione:

+
`system node autosupport invoke -node * -type all -message MAINT=end`

. Ripetere il comando sul cluster partner.




== Attivazione della modalità di transizione e disattivazione del cluster ha

È necessario attivare la modalità di transizione MetroCluster per consentire ai nodi vecchi e nuovi di operare insieme nella configurazione MetroCluster e disattivare il cluster ha.

. Attiva transizione:
+
.. Passare al livello di privilegio avanzato:
+
`set -privilege advanced`

.. Attiva modalità di transizione:
+
`metrocluster transition enable -transition-mode non-disruptive`

+

NOTE: Eseguire questo comando su un solo cluster.

+
....
cluster_A::*> metrocluster transition enable -transition-mode non-disruptive

Warning: This command enables the start of a "non-disruptive" MetroCluster
         FC-to-IP transition. It allows the addition of hardware for another DR
         group that uses IP fabrics, and the removal of a DR group that uses FC
         fabrics. Clients will continue to access their data during a
         non-disruptive transition.

         Automatic unplanned switchover will also be disabled by this command.
Do you want to continue? {y|n}: y

cluster_A::*>

....
.. Tornare al livello di privilegio admin:
+
`set -privilege admin`



. Verificare che la transizione sia attivata su entrambi i cluster.
+
....

cluster_A::> metrocluster transition show-mode
Transition Mode

non-disruptive

cluster_A::*>


cluster_B::*> metrocluster transition show-mode
Transition Mode

non-disruptive

Cluster_B::>

....
. Disattiva cluster ha.
+

NOTE: È necessario eseguire questo comando su entrambi i cluster.

+
....
cluster_A::*> cluster ha modify -configured false

Warning: This operation will unconfigure cluster HA. Cluster HA must be
configured on a two-node cluster to ensure data access availability in
the event of storage failover.
Do you want to continue? {y|n}: y
Notice: HA is disabled.

cluster_A::*>


cluster_B::*> cluster ha modify -configured false

Warning: This operation will unconfigure cluster HA. Cluster HA must be
configured on a two-node cluster to ensure data access availability in
the event of storage failover.
Do you want to continue? {y|n}: y
Notice: HA is disabled.

cluster_B::*>
....
. Verificare che il cluster ha sia disattivato.
+

NOTE: È necessario eseguire questo comando su entrambi i cluster.

+
....
cluster_A::> cluster ha show

High Availability Configured: false
Warning: Cluster HA has not been configured. Cluster HA must be configured
on a two-node cluster to ensure data access availability in the
event of storage failover. Use the "cluster ha modify -configured
true" command to configure cluster HA.

cluster_A::>

cluster_B::> cluster ha show

High Availability Configured: false
Warning: Cluster HA has not been configured. Cluster HA must be configured
on a two-node cluster to ensure data access availability in the
event of storage failover. Use the "cluster ha modify -configured
true" command to configure cluster HA.

cluster_B::>
....




== Unione dei nodi IP MetroCluster ai cluster

È necessario aggiungere i quattro nuovi nodi IP MetroCluster alla configurazione MetroCluster esistente.

.A proposito di questa attività
È necessario eseguire questa attività su entrambi i cluster.

.Fasi
. Aggiungere i nodi IP MetroCluster alla configurazione MetroCluster esistente.
+
.. Collegare il primo nodo IP MetroCluster (Node_A_3-IP) alla configurazione FC MetroCluster esistente.
+
....

Welcome to the cluster setup wizard.

You can enter the following commands at any time:
  "help" or "?" - if you want to have a question clarified,
  "back" - if you want to change previously answered questions, and
  "exit" or "quit" - if you want to quit the cluster setup wizard.
     Any changes you made before quitting will be saved.

You can return to cluster setup at any time by typing "cluster setup".
To accept a default or omit a question, do not enter a value.

This system will send event messages and periodic reports to NetApp Technical
Support. To disable this feature, enter autosupport modify -support disable
within 24 hours.

Enabling AutoSupport can significantly speed problem determination and
resolution, should a problem occur on your system.
For further information on AutoSupport, see:
http://support.netapp.com/autosupport/

Type yes to confirm and continue {yes}: yes

Enter the node management interface port [e0M]:
Enter the node management interface IP address: 172.17.8.93
Enter the node management interface netmask: 255.255.254.0
Enter the node management interface default gateway: 172.17.8.1
A node management interface on port e0M with IP address 172.17.8.93 has been created.

Use your web browser to complete cluster setup by accessing https://172.17.8.93

Otherwise, press Enter to complete cluster setup using the command line
interface:

Do you want to create a new cluster or join an existing cluster? {create, join}:
join


Existing cluster interface configuration found:

Port    MTU     IP              Netmask
e0c     9000    169.254.148.217 255.255.0.0
e0d     9000    169.254.144.238 255.255.0.0

Do you want to use this configuration? {yes, no} [yes]: yes
.
.
.
....
.. Collegare il secondo nodo IP MetroCluster (Node_A_4-IP) alla configurazione FC MetroCluster esistente.


. Ripetere questa procedura per unire Node_B_3-IP e Node_B_4-IP a cluster_B.




== Configurazione delle LIF tra cluster, creazione delle interfacce MetroCluster e mirroring degli aggregati root

È necessario creare le LIF di peering del cluster e le interfacce MetroCluster sui nuovi nodi IP MetroCluster.

.A proposito di questa attività
La porta home utilizzata negli esempi è specifica per la piattaforma. Utilizzare la porta home appropriata specifica per la piattaforma del nodo IP MetroCluster.

.Fasi
. Sui nuovi nodi IP MetroCluster, link:../install-ip/task_sw_config_configure_clusters.html#configuring-intercluster-lifs-for-cluster-peering["Configurare le LIF dell'intercluster"].
. In ogni sito, verificare che il peering del cluster sia configurato:
+
`cluster peer show`

+
L'esempio seguente mostra la configurazione del peering del cluster su cluster_A:

+
....
cluster_A:> cluster peer show
Peer Cluster Name         Cluster Serial Number Availability   Authentication
------------------------- --------------------- -------------- --------------
cluster_B                 1-80-000011           Available      ok
....
+
L'esempio seguente mostra la configurazione del peering del cluster su cluster_B:

+
....
cluster_B:> cluster peer show
Peer Cluster Name         Cluster Serial Number Availability   Authentication
------------------------- --------------------- -------------- --------------
cluster_A 1-80-000011 Available ok
....
. Configurare il gruppo di DR per i nodi IP MetroCluster:
+
`metrocluster configuration-settings dr-group create -partner-cluster`

+
....
cluster_A::> metrocluster configuration-settings dr-group create -partner-cluster
cluster_B -local-node node_A_3-IP -remote-node node_B_3-IP
[Job 259] Job succeeded: DR Group Create is successful.
cluster_A::>
....
. Verificare che il gruppo DR sia stato creato.
+
`metrocluster configuration-settings dr-group show`

+
....
cluster_A::> metrocluster configuration-settings dr-group show

DR Group ID Cluster                    Node               DR Partner Node
----------- -------------------------- ------------------ ------------------
2           cluster_A
                                       node_A_3-IP        node_B_3-IP
                                       node_A_4-IP        node_B_4-IP
            cluster_B
                                       node_B_3-IP        node_A_3-IP
                                       node_B_4-IP        node_A_4-IP

4 entries were displayed.

cluster_A::>
....
+
Si noterà che il gruppo DR per i vecchi nodi FC MetroCluster (gruppo DR 1) non viene elencato quando si esegue `metrocluster configuration-settings dr-group show` comando.

+
È possibile utilizzare `metrocluster node show` su entrambi i siti per elencare tutti i nodi.

+
....
cluster_A::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node_A_1-FC         configured     enabled   normal
              node_A_2-FC         configured     enabled   normal
      cluster_B
              node_B_1-FC         configured     enabled   normal
              node_B_2-FC         configured     enabled   normal
2     cluster_A
              node_A_3-IP      ready to configure
                                                -         -
              node_A_4-IP      ready to configure
                                                -         -

cluster_B::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_B
              node_B_1-FC         configured     enabled   normal
              node_B_2-FC         configured     enabled   normal
      cluster_A
              node_A_1-FC         configured     enabled   normal
              node_A_2-FC         configured     enabled   normal
2     cluster_B
              node_B_3-IP      ready to configure
                                                -         -
              node_B_4-IP      ready to configure
                                                -         -
....
. Configurare le interfacce IP MetroCluster per i nodi IP MetroCluster appena entrati:
+
`metrocluster configuration-settings interface create -cluster-name`

+
Vedere link:../install-ip/task_sw_config_configure_clusters.html#configuring-and-connecting-the-metrocluster-ip-interfaces["Configurazione e connessione delle interfacce IP di MetroCluster"] Per considerazioni sulla configurazione delle interfacce IP.

+

NOTE: È possibile configurare le interfacce IP di MetroCluster da entrambi i cluster. Inoltre, a partire da ONTAP 9.9.1, se si utilizza una configurazione Layer 3, è necessario specificare anche `-gateway` Parametro durante la creazione di interfacce IP MetroCluster. Fare riferimento a. link:../install-ip/concept_considerations_layer_3.html["Considerazioni per le reti wide-area di livello 3"]

+
....
cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_3-IP -home-port e1a -address 172.17.26.10 -netmask 255.255.255.0
[Job 260] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_3-IP -home-port e1b -address 172.17.27.10 -netmask 255.255.255.0
[Job 261] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_4-IP -home-port e1a -address 172.17.26.11 -netmask 255.255.255.0
[Job 262] Job succeeded: Interface Create is successful.

cluster_A::> :metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_4-IP -home-port e1b -address 172.17.27.11 -netmask 255.255.255.0
[Job 263] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_3-IP -home-port e1a -address 172.17.26.12 -netmask 255.255.255.0
[Job 264] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_3-IP -home-port e1b -address 172.17.27.12 -netmask 255.255.255.0
[Job 265] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_4-IP -home-port e1a -address 172.17.26.13 -netmask 255.255.255.0
[Job 266] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_4-IP -home-port e1b -address 172.17.27.13 -netmask 255.255.255.0
[Job 267] Job succeeded: Interface Create is successful.
....
. Verificare che le interfacce IP MetroCluster siano state create:
+
`metrocluster configuration-settings interface show`

+
....
cluster_A::>metrocluster configuration-settings interface show

DR                                                                    Config
Group Cluster Node    Network Address Netmask         Gateway         State
----- ------- ------- --------------- --------------- --------------- ---------
2     cluster_A
             node_A_3-IP
                 Home Port: e1a
                      172.17.26.10    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.10    255.255.255.0   -               completed
              node_A_4-IP
                 Home Port: e1a
                      172.17.26.11    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.11    255.255.255.0   -               completed
      cluster_B
             node_B_3-IP
                 Home Port: e1a
                      172.17.26.13    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.13    255.255.255.0   -               completed
              node_B_3-IP
                 Home Port: e1a
                      172.17.26.12    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.12    255.255.255.0   -               completed
8 entries were displayed.

cluster_A>
....
. Collegare le interfacce IP di MetroCluster:
+
`metrocluster configuration-settings connection connect`

+

NOTE: Il completamento di questo comando potrebbe richiedere alcuni minuti.

+
....
cluster_A::> metrocluster configuration-settings connection connect

cluster_A::>
....
. Verificare che le connessioni siano state stabilite correttamente:
+
`metrocluster configuration-settings connection show`

+
....
cluster_A::> metrocluster configuration-settings connection show

DR                    Source          Destination
Group Cluster Node    Network Address Network Address Partner Type Config State
----- ------- ------- --------------- --------------- ------------ ------------
2     cluster_A
              node_A_3-IP**
                 Home Port: e1a
                      172.17.26.10    172.17.26.11    HA Partner   completed
                 Home Port: e1a
                      172.17.26.10    172.17.26.12    DR Partner   completed
                 Home Port: e1a
                      172.17.26.10    172.17.26.13    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.11    HA Partner   completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.12    DR Partner   completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.13    DR Auxiliary completed
              node_A_4-IP
                 Home Port: e1a
                      172.17.26.11    172.17.26.10    HA Partner   completed
                 Home Port: e1a
                      172.17.26.11    172.17.26.13    DR Partner   completed
                 Home Port: e1a
                      172.17.26.11    172.17.26.12    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.10    HA Partner   completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.13    DR Partner   completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.12    DR Auxiliary completed

DR                    Source          Destination
Group Cluster Node    Network Address Network Address Partner Type Config State
----- ------- ------- --------------- --------------- ------------ ------------
2     cluster_B
              node_B_4-IP
                 Home Port: e1a
                      172.17.26.13    172.17.26.12    HA Partner   completed
                 Home Port: e1a
                      172.17.26.13    172.17.26.11    DR Partner   completed
                 Home Port: e1a
                      172.17.26.13    172.17.26.10    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.12    HA Partner   completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.11    DR Partner   completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.10    DR Auxiliary completed
              node_B_3-IP
                 Home Port: e1a
                      172.17.26.12    172.17.26.13    HA Partner   completed
                 Home Port: e1a
                      172.17.26.12    172.17.26.10    DR Partner   completed
                 Home Port: e1a
                      172.17.26.12    172.17.26.11    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.13    HA Partner   completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.10    DR Partner   completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.11    DR Auxiliary completed
24 entries were displayed.

cluster_A::>
....
. Verificare l'assegnazione automatica e il partizionamento dei dischi:
+
`disk show -pool Pool1`

+
....
cluster_A::> disk show -pool Pool1
                     Usable           Disk    Container   Container
Disk                   Size Shelf Bay Type    Type        Name      Owner
---------------- ---------- ----- --- ------- ----------- --------- --------
1.10.4                    -    10   4 SAS     remote      -         node_B_2
1.10.13                   -    10  13 SAS     remote      -         node_B_2
1.10.14                   -    10  14 SAS     remote      -         node_B_1
1.10.15                   -    10  15 SAS     remote      -         node_B_1
1.10.16                   -    10  16 SAS     remote      -         node_B_1
1.10.18                   -    10  18 SAS     remote      -         node_B_2
...
2.20.0              546.9GB    20   0 SAS     aggregate   aggr0_rha1_a1 node_a_1
2.20.3              546.9GB    20   3 SAS     aggregate   aggr0_rha1_a2 node_a_2
2.20.5              546.9GB    20   5 SAS     aggregate   rha1_a1_aggr1 node_a_1
2.20.6              546.9GB    20   6 SAS     aggregate   rha1_a1_aggr1 node_a_1
2.20.7              546.9GB    20   7 SAS     aggregate   rha1_a2_aggr1 node_a_2
2.20.10             546.9GB    20  10 SAS     aggregate   rha1_a1_aggr1 node_a_1
...
43 entries were displayed.
cluster_A::>
....
+

NOTE: Nei sistemi configurati per Advanced Drive Partitioning (ADP), il tipo di container è "condiviso" piuttosto che "remoto", come mostrato nell'output di esempio.

. Mirroring degli aggregati root:
+
`storage aggregate mirror -aggregate aggr0_node_A_3_IP`

+

NOTE: È necessario completare questo passaggio su ciascun nodo IP MetroCluster.

+
....
cluster_A::> aggr mirror -aggregate aggr0_node_A_3_IP

Info: Disks would be added to aggregate "aggr0_node_A_3_IP"on node "node_A_3-IP"
      in the following manner:

      Second Plex

        RAID Group rg0, 3 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    4.20.0                    SAS               -        -
          parity     4.20.3                    SAS               -        -
          data       4.20.1                    SAS         546.9GB  558.9GB

      Aggregate capacity available for volume use would be 467.6GB.

Do you want to continue? {y|n}: y

cluster_A::>
....
. Verificare che gli aggregati root siano mirrorati:
+
`storage aggregate show`

+
....
cluster_A::> aggr show

Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
aggr0_node_A_1_FC
           349.0GB   16.84GB   95% online       1 node_A_1-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_2_FC
           349.0GB   16.84GB   95% online       1 node_A_2-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_3_IP
           467.6GB   22.63GB   95% online       1 node_A_3-IP      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_4_IP
           467.6GB   22.62GB   95% online       1 node_A_4-IP      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr_data_a1
            1.02TB    1.01TB    1% online       1 node_A_1-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr_data_a2
            1.02TB    1.01TB    1% online       1 node_A_2-FC      raid_dp,
                                                                   mirrored,
....




== Finalizzazione dell'aggiunta dei nodi IP MetroCluster

È necessario incorporare il nuovo gruppo DR nella configurazione MetroCluster e creare aggregati di dati mirrorati sui nuovi nodi.

.Fasi
. Configurare MetroCluster in base all'eventuale presenza di uno o più aggregati di dati:
+
|===


| Se la configurazione di MetroCluster dispone di... | Quindi... 


 a| 
Aggregati di dati multipli
 a| 
Dal prompt di qualsiasi nodo, configurare MetroCluster:

`metrocluster configure _node-name_`


NOTE: Devi eseguire `metrocluster configure` e *non* `metrocluster configure -refresh true`



 a| 
Un singolo aggregato di dati mirrorato
 a| 
.. Dal prompt di qualsiasi nodo, passare al livello di privilegio avanzato:
+
`set -privilege advanced`

+
Devi rispondere con `y` quando viene richiesto di passare alla modalità avanzata e viene visualizzato il prompt della modalità avanzata (*).

.. Configurare MetroCluster con `-allow-with-one-aggregate true` parametro:
+
`metrocluster configure -allow-with-one-aggregate true _node-name_`

.. Tornare al livello di privilegio admin:
+
`set -privilege admin`



|===
+

NOTE: La Best practice consiste nell'avere più aggregati di dati mirrorati. Quando è presente un solo aggregato mirrorato, la protezione è inferiore perché i volumi di metadati si trovano sullo stesso aggregato piuttosto che su aggregati separati.

. Verificare che i nodi siano aggiunti al gruppo di DR:
+
`metrocluster node show`

+
....
cluster_A::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node-A-1-FC        configured     enabled   normal
              node-A-2-FC        configured     enabled   normal
      Cluster-B
              node-B-1-FC        configured     enabled   normal
              node-B-2-FC        configured     enabled   normal
2     cluster_A
              node-A-3-IP        configured     enabled   normal
              node-A-4-IP        configured     enabled   normal
      Cluster-B
              node-B-3-IP        configured     enabled   normal
              node-B-4-IP        configured     enabled   normal
8 entries were displayed.

cluster_A::>
....
. Creare aggregati di dati mirrorati su ciascuno dei nuovi nodi MetroCluster:
+
`storage aggregate create -aggregate aggregate-name -node node-name -diskcount no-of-disks -mirror true`

+

NOTE: È necessario creare almeno un aggregato di dati mirrorati per sito. Si consiglia di disporre di due aggregati di dati mirrorati per sito su nodi IP MetroCluster per ospitare i volumi MDV, tuttavia è supportato un singolo aggregato per sito (ma non consigliato). È possibile che un sito di MetroCluster disponga di un singolo aggregato di dati mirrorati e l'altro sito disponga di più aggregato di dati mirrorati.

+
Nell'esempio seguente viene illustrata la creazione di un aggregato su Node_A_3-IP.

+
....
cluster_A::> storage aggregate create -aggregate data_a3 -node node_A_3-IP -diskcount 10 -mirror t

Info: The layout for aggregate "data_a3" on node "node_A_3-IP" would be:

      First Plex

        RAID Group rg0, 5 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    5.10.15                   SAS               -        -
          parity     5.10.16                   SAS               -        -
          data       5.10.17                   SAS         546.9GB  547.1GB
          data       5.10.18                   SAS         546.9GB  558.9GB
          data       5.10.19                   SAS         546.9GB  558.9GB

      Second Plex

        RAID Group rg0, 5 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    4.20.17                   SAS               -        -
          parity     4.20.14                   SAS               -        -
          data       4.20.18                   SAS         546.9GB  547.1GB
          data       4.20.19                   SAS         546.9GB  547.1GB
          data       4.20.16                   SAS         546.9GB  547.1GB

      Aggregate capacity available for volume use would be 1.37TB.

Do you want to continue? {y|n}: y
[Job 440] Job succeeded: DONE

cluster_A::>
....
. Verificare che sia possibile il Takeover e che i nodi siano connessi eseguendo il seguente comando su entrambi i cluster:
+
`storage failover show`

+
[listing]
----
cluster_A::> storage failover show
                                    Takeover
Node           Partner              Possible    State Description
-------------- -------------------- ---------   ------------------
Node_FC_1      Node_FC_2              true      Connected to Node_FC_2
Node_FC_2      Node_FC_1              true      Connected to Node_FC_1
Node_IP_1      Node_IP_2              true      Connected to Node_IP_2
Node_IP_2      Node_IP_1              true      Connected to Node_IP_1
----
. Spostare i volumi MDV_CRS dai vecchi nodi ai nuovi nodi con privilegi avanzati.
+
.. Visualizzare i volumi per identificare i volumi MDV:
+

NOTE: Se si dispone di un singolo aggregato di dati mirrorati per sito, spostare entrambi i volumi MDV in questo singolo aggregato. Se si dispone di due o più aggregati di dati mirrorati, spostare ciascun volume MDV in un aggregato diverso.

+
L'esempio seguente mostra i volumi MDV nel volume che mostrano l'output:

+
....
cluster_A::> volume show
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
...

cluster_A   MDV_CRS_2c78e009ff5611e9b0f300a0985ef8c4_A
                       aggr_b1      -          RW            -          -     -
cluster_A   MDV_CRS_2c78e009ff5611e9b0f300a0985ef8c4_B
                       aggr_b2      -          RW            -          -     -
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_A
                       aggr_a1      online     RW         10GB     9.50GB    0%
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
                       aggr_a2      online     RW         10GB     9.50GB    0%
...
11 entries were displayed.mple
....
.. Impostare il livello di privilegio avanzato:
+
`set -privilege advanced`

.. Spostare i volumi MDV uno alla volta:
+
`volume move start -volume mdv-volume -destination-aggregate aggr-on-new-node -vserver vserver-name`

+
L'esempio seguente mostra il comando e l'output per lo spostamento di MDV_CRS_d6b0b313ff5611e9837100a098544e51_A per aggregare data_a3 sul nodo_A_3.

+
....
cluster_A::*> vol move start -volume MDV_CRS_d6b0b313ff5611e9837100a098544e51_A -destination-aggregate data_a3 -vserver cluster_A

Warning: You are about to modify the system volume
         "MDV_CRS_d6b0b313ff5611e9837100a098544e51_A". This might cause severe
         performance or stability problems. Do not proceed unless directed to
         do so by support. Do you want to proceed? {y|n}: y
[Job 494] Job is queued: Move "MDV_CRS_d6b0b313ff5611e9837100a098544e51_A" in Vserver "cluster_A" to aggregate "data_a3". Use the "volume move show -vserver cluster_A -volume MDV_CRS_d6b0b313ff5611e9837100a098544e51_A" command to view the status of this operation.
....
.. Utilizzare il comando di visualizzazione del volume per verificare che il volume MDV sia stato spostato correttamente:
+
`volume show mdv-name`

+
Il seguente output indica che il volume MDV è stato spostato correttamente.

+
....
cluster_A::*> vol show MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
Vserver     Volume       Aggregate    State      Type       Size  Available Used%
---------   ------------ ------------ ---------- ---- ---------- ---------- -----
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
                       aggr_a2      online     RW         10GB     9.50GB    0%
....
.. Tornare alla modalità admin:
+
`set -privilege admin`




